{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa59e480",
   "metadata": {},
   "source": [
    "Pierwszym krokiem będzie zaimplementowanie sieci neuronowej na używanym wcześniej zestawie Fashion-Mnist tak, aby uzyskać wynik na danych testowych rzędu accuracy > 0.94 (albo jak najbardziej zbliżony), używając poniższego podziału:\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(images, labels, test_size=0.1, random_state=10, stratify=labels)\n",
    "    \n",
    "Drugim krokiem będzie zapisanie i dostarczenie modelu oraz napisanie interfejsu, który przyjmuje wartość wejściową oraz zwraca wartość przewidzianą przez nasz model wraz z wyrysowanym obrazem wejściowym (aby można było zweryfikować wizualnie, czy działa).\n",
    "\n",
    "W kursie nie mówiliśmy jak tego dokonać, choć zapisywanie modeli jest opisane na stronie TensorFlow. Mentorzy z chęcią pomogą, lecz zachęcamy do odkrycia, jak to zrobić samemu.\n",
    "\n",
    "Trzecim krokiem będzie podbicie naszego wyniku do około 0.97 poprzez użycie technik augumentacji, czyli tworzenia nowy danych na bazie danych już istniejących. Jest to przydatna technika, o którą pytanie pojawia się podczas rozmów o pracę :)\n",
    "\n",
    "Będzie to relatywnie trudne, gdyż posiadamy mało danych treningowych, więc należy zrobić mały \"research\" w poszukiwaniu informacji, jak takie dane sobie wygenerować.\n",
    "\n",
    "Polecamy szczególnie:\n",
    "\n",
    "Albumentation library\n",
    "Open CV library\n",
    "Ten kurs ma pokazywać, jak w rzeczywistości pracuje się z TensorFlow, a realia są takie, że bardzo często większość pracy to odkrywanie nowych rzeczy. Dlatego podajemy tylko linki do bibliotek – jak należy ich użyć, trzeba wywnioskować samemu :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4ceb95",
   "metadata": {},
   "source": [
    "# Import Bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4471e09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podstawy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "86a30c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wizualizacja\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "de4b89bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import danych\n",
    "\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c41c97c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sieci neuronowe\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5a848ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metryki\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e2ae18f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Albumentacja\n",
    "import albumentations as A\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bd3a63",
   "metadata": {},
   "source": [
    "# Import i obróbka Danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3144d2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = fashion_mnist.load_data()\n",
    "images, labels = train\n",
    "\n",
    "images = images/255.0\n",
    "\n",
    "labels = labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d6f7fc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.1, random_state=10, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "16e20682",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "340586ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.shuffle(1000).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d7a270",
   "metadata": {},
   "source": [
    "Klasy oraz ich nazwy\n",
    "\n",
    "Label\tDescription\n",
    "\n",
    "0\tT-shirt/top\n",
    "\n",
    "1\tTrouser\n",
    "\n",
    "2\tPullover\n",
    "\n",
    "3\tDress\n",
    "\n",
    "4\tCoat\n",
    "\n",
    "5\tSandal\n",
    "\n",
    "6\tShirt\n",
    "\n",
    "7\tSneaker\n",
    "\n",
    "8\tBag\n",
    "\n",
    "9\tAnkle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d209570",
   "metadata": {},
   "source": [
    "# Tworzenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "992a469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(16, activation='relu', name=\"input_layer\"),\n",
    "        tf.keras.layers.Dense(64, activation='relu', name=\"hidden_layer_1\"),\n",
    "        tf.keras.layers.Dense(32, activation='relu', name=\"hidden_layer_2\"),\n",
    "        tf.keras.layers.Dense(10, activation='softmax', name=\"output_layer\")\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e716e8f7",
   "metadata": {},
   "source": [
    "Zapisujemy wagi za każdym razem kiedy model oszacuje lepsze od poprzednich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2324f048",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1,\n",
    "                                                 save_best_only=True,\n",
    "                                                 monitor='val_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8fa502",
   "metadata": {},
   "source": [
    "# Szkolenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f9031dfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1656/1688 [============================>.] - ETA: 0s - loss: 0.6005 - accuracy: 0.7882WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 3s 1ms/step - loss: 0.5978 - accuracy: 0.7892\n",
      "Epoch 2/10\n",
      "1662/1688 [============================>.] - ETA: 0s - loss: 0.4210 - accuracy: 0.8496WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.4212 - accuracy: 0.8495\n",
      "Epoch 3/10\n",
      "1666/1688 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8600WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.3850 - accuracy: 0.8601\n",
      "Epoch 4/10\n",
      "1679/1688 [============================>.] - ETA: 0s - loss: 0.3656 - accuracy: 0.8671WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.3654 - accuracy: 0.8673\n",
      "Epoch 5/10\n",
      "1686/1688 [============================>.] - ETA: 0s - loss: 0.3507 - accuracy: 0.8717WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.3506 - accuracy: 0.8717\n",
      "Epoch 6/10\n",
      "1674/1688 [============================>.] - ETA: 0s - loss: 0.3366 - accuracy: 0.8763WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.3364 - accuracy: 0.8764\n",
      "Epoch 7/10\n",
      "1679/1688 [============================>.] - ETA: 0s - loss: 0.3286 - accuracy: 0.8791WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.3283 - accuracy: 0.8792\n",
      "Epoch 8/10\n",
      "1684/1688 [============================>.] - ETA: 0s - loss: 0.3192 - accuracy: 0.8814WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.3191 - accuracy: 0.8815\n",
      "Epoch 9/10\n",
      "1680/1688 [============================>.] - ETA: 0s - loss: 0.3109 - accuracy: 0.8855WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3107 - accuracy: 0.8857\n",
      "Epoch 10/10\n",
      "1662/1688 [============================>.] - ETA: 0s - loss: 0.3063 - accuracy: 0.8865WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.3061 - accuracy: 0.8866\n"
     ]
    }
   ],
   "source": [
    "model_fashion = create_model()\n",
    "\n",
    "stats = model_fashion.fit(train_ds, epochs=10, verbose=1, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c4e6d9",
   "metadata": {},
   "source": [
    "Model widocznie zwolnił po trzeciej epoce. Podnosząc liczbę epok doszedłbym do wyniku accuracy na poziomie 0.94.\n",
    "\n",
    "Odpalę model jeszcze raz, żeby przeleciał ponownie. Powinienem uzyskać wyższy wynik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "add819c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1678/1688 [============================>.] - ETA: 0s - loss: 0.2975 - accuracy: 0.8889WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.2976 - accuracy: 0.8889\n",
      "Epoch 2/10\n",
      "1661/1688 [============================>.] - ETA: 0s - loss: 0.2962 - accuracy: 0.8891WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.2961 - accuracy: 0.8892\n",
      "Epoch 3/10\n",
      "1656/1688 [============================>.] - ETA: 0s - loss: 0.2889 - accuracy: 0.8923WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.2887 - accuracy: 0.8924\n",
      "Epoch 4/10\n",
      "1666/1688 [============================>.] - ETA: 0s - loss: 0.2833 - accuracy: 0.8932WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.2836 - accuracy: 0.8934\n",
      "Epoch 5/10\n",
      "1671/1688 [============================>.] - ETA: 0s - loss: 0.2770 - accuracy: 0.8955WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.2772 - accuracy: 0.8956\n",
      "Epoch 6/10\n",
      "1662/1688 [============================>.] - ETA: 0s - loss: 0.2733 - accuracy: 0.8970WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.2736 - accuracy: 0.8971\n",
      "Epoch 7/10\n",
      "1662/1688 [============================>.] - ETA: 0s - loss: 0.2708 - accuracy: 0.8963WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.2706 - accuracy: 0.8965\n",
      "Epoch 8/10\n",
      "1656/1688 [============================>.] - ETA: 0s - loss: 0.2674 - accuracy: 0.8992WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.2675 - accuracy: 0.8992\n",
      "Epoch 9/10\n",
      "1679/1688 [============================>.] - ETA: 0s - loss: 0.2666 - accuracy: 0.8983WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.2662 - accuracy: 0.8984\n",
      "Epoch 10/10\n",
      "1666/1688 [============================>.] - ETA: 0s - loss: 0.2611 - accuracy: 0.9025WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.2610 - accuracy: 0.9026\n"
     ]
    }
   ],
   "source": [
    "stats = model_fashion.fit(train_ds, epochs=10, verbose=1, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1acb54d",
   "metadata": {},
   "source": [
    "Wynik został podniesiony o 1,5%. Działanie to było bezcelowe, mogłem po prostu zwiększyć ilość epok przy pierwszym treningu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f61b4a1",
   "metadata": {},
   "source": [
    "Zapisujemy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "06ba9fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file -p already exists.\n",
      "Error occurred while processing: -p.\n",
      "A subdirectory or file saved_model already exists.\n",
      "Error occurred while processing: saved_model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/model_fashion\\assets\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p saved_model\n",
    "model_fashion.save('saved_model/model_fashion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc35d13",
   "metadata": {},
   "source": [
    "# Ewalucja modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "202c3d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, stats):\n",
    "    \n",
    "    # Numeryczne predykcje\n",
    "    y_pred = model_fashion.predict(X_test)\n",
    "    print(\"probs : \", y_pred[2])\n",
    "    print(\"klasa :\", np.argmax(y_pred[2]))\n",
    "    print(\"rzeczywista klasa: \", y_test[2])\n",
    "    \n",
    "    # Wizualizacja wyników treningu modelu\n",
    "    pd.DataFrame(stats.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.show()\n",
    "    \n",
    "    # Mierzymy F1 Score\n",
    "    y_pred = np.argmax(y_pred,axis=1)\n",
    "    scores = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f'F1 Score modelu to {scores}')\n",
    "    \n",
    "    # Dodajmy heatmap składającą się z błędnych predykcji modelu, żeby zobaczyć z którymi obrazami nasz model ma problem\n",
    "    conf_mx = confusion_matrix(y_test, y_pred)\n",
    "    row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "    norm_conf_mx = conf_mx / row_sums\n",
    "    np.fill_diagonal(norm_conf_mx, 0)\n",
    "    plt.matshow(conf_mx, cmap='Dark2')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    # Właściwy obraz etykiety\n",
    "    plt.imshow(np.array(X_test[2]))\n",
    "    plt.title('Właściwy obraz')\n",
    "    plt.title(y_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "55eed121",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 979us/step\n",
      "probs :  [1.1034963e-06 6.2640680e-08 6.0364113e-05 1.6442084e-09 2.6003090e-07\n",
      " 2.2643225e-04 4.1734990e-07 9.9968982e-01 1.3424043e-05 8.1033313e-06]\n",
      "klasa : 7\n",
      "rzeczywista klasa:  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score modelu to 0.881516510841249\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(model_fashion, X_test, y_test, stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0887da86",
   "metadata": {},
   "source": [
    "Model prawidłowo zaklasyfikował obraz, jednakże ma kilka problemów.\n",
    "\n",
    "Wyświetlone predykcje wskazują nam, że podany obraz, w dużym stopniu, przypominał modelowi obiekty z klas 3,4,6 tj. Dress, Coat, Shirt, co jest dosyć nietypowe. Dodatkowo Model często myli obiekty Shirt z T-Shirt oraz Pullover, jak widać na Confusion Matrix. Wydaje mi się to naturalne z powodu podobieństwa kroju tych ubrań. Warto sprawdzić jak wyglądają obiekty tych klas i zastanowić się w jaki sposób możemy pomóc modelowi je rozróżnić.\n",
    "\n",
    "Model otrzymał wysoki wynik F1 Score, jednak można go znacznie poprawić.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2413f74c",
   "metadata": {},
   "source": [
    "Komentarz wyżej pisałem dzień wcześniej. Dzisiaj wyniki wyglądają innaczej, są lepsze i nie widać ewidentnych pomyłek modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e80949",
   "metadata": {},
   "source": [
    "# Tworzenie nowych danych przy pomocy Albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3b45d37e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "def albumentation(data):\n",
    "    \n",
    "    fliped_images = []\n",
    "    \n",
    "    for image in data:\n",
    "        \n",
    "        # Declare an augmentation pipeline\n",
    "        transform = A.Compose([\n",
    "        A.HorizontalFlip(p=1),\n",
    "        A.GaussNoise(var_limit=(0.0001, 0.017), always_apply=True)\n",
    "        ])\n",
    "        \n",
    "        transformed = transform(image=image)\n",
    "        new_image = transformed['image']\n",
    "        fliped_images.append(new_image)\n",
    "        \n",
    "        \n",
    "        \n",
    "    images_2 = np.array(fliped_images)\n",
    "    \n",
    "    return images_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d98cfa9",
   "metadata": {},
   "source": [
    "Tworzymy nowe obrazy z użyciem funkcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a98697dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2, test_2 = fashion_mnist.load_data()\n",
    "images_2, labels_2 = train_2\n",
    "\n",
    "images_2 = images_2/255.0\n",
    "\n",
    "labels_2 = labels_2.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f531a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_images = albumentation(images_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ac51476c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(new_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e787006f",
   "metadata": {},
   "source": [
    "Dzielimy dane ponownie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "36a9bff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(new_images, labels_2, test_size=0.1, random_state=10, stratify=labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "746138fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_2 = tf.data.Dataset.from_tensor_slices((X_train_2, y_train_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "62143b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_2 = train_ds_2.shuffle(1000).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c6e595",
   "metadata": {},
   "source": [
    "Trenujemy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ff6494f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1664/1688 [============================>.] - ETA: 0s - loss: 0.4798 - accuracy: 0.8289WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.4781 - accuracy: 0.8296\n",
      "Epoch 2/10\n",
      "1676/1688 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8591WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 3s 1ms/step - loss: 0.3831 - accuracy: 0.8593\n",
      "Epoch 3/10\n",
      "1656/1688 [============================>.] - ETA: 0s - loss: 0.3577 - accuracy: 0.8683WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3578 - accuracy: 0.8682\n",
      "Epoch 4/10\n",
      "1681/1688 [============================>.] - ETA: 0s - loss: 0.3414 - accuracy: 0.8739WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3413 - accuracy: 0.8739\n",
      "Epoch 5/10\n",
      "1682/1688 [============================>.] - ETA: 0s - loss: 0.3282 - accuracy: 0.8792WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3283 - accuracy: 0.8791\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - ETA: 0s - loss: 0.3188 - accuracy: 0.8822WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3188 - accuracy: 0.8822\n",
      "Epoch 7/10\n",
      "1681/1688 [============================>.] - ETA: 0s - loss: 0.3087 - accuracy: 0.8848WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3086 - accuracy: 0.8848\n",
      "Epoch 8/10\n",
      "1674/1688 [============================>.] - ETA: 0s - loss: 0.2993 - accuracy: 0.8896WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.2991 - accuracy: 0.8897\n",
      "Epoch 9/10\n",
      "1672/1688 [============================>.] - ETA: 0s - loss: 0.2930 - accuracy: 0.8917WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 3s 1ms/step - loss: 0.2928 - accuracy: 0.8917\n",
      "Epoch 10/10\n",
      "1676/1688 [============================>.] - ETA: 0s - loss: 0.2858 - accuracy: 0.8922WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.2861 - accuracy: 0.8921\n"
     ]
    }
   ],
   "source": [
    "stats = model_fashion.fit(train_ds_2, epochs=10, verbose=1, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d5fb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
